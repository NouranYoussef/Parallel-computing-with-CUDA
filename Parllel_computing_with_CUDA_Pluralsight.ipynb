{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains my notes and implementation of some coding examples in [Parallel computing with CUDA](https://app.pluralsight.com/library/courses/parallel-computing-cuda) by Dmitri Nesteruk on Pluralsight"
      ],
      "metadata": {
        "id": "UAhhYkn5E0FL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA set-up"
      ],
      "metadata": {
        "id": "gXGbZQrEJ6Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking installed CUDA/nvcc \n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvjIjDPVJVde",
        "outputId": "765d1ddc-79e3-4349-8d0c-03594464d132"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the given command to install an extension to run nvcc from the Notebook cells\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbrXJy7pJcwN",
        "outputId": "f4b3eced-d138-477a-eced-d5c74568766a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-iqhnb3g3\n",
            "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-iqhnb3g3\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4306 sha256=f3fa4069d2c03195ef87cf157858b1913485c96e76c36564ce881a9d50fb1b6f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gs96kw08/wheels/ca/33/8d/3c86eb85e97d2b6169d95c6e8f2c297fdec60db6e84cb56f5e\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the extension\n",
        "%load_ext nvcc_plugin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VYL_imLJh9Q",
        "outputId": "35078b9c-b600-41fe-9692-c54db2e81255"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to CUDA C/C++"
      ],
      "metadata": {
        "id": "DBVcyLT-J_29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hello , CUDA"
      ],
      "metadata": {
        "id": "k6dY7RbLdA3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding array elements without cuda"
      ],
      "metadata": {
        "id": "u5qeFSCdIZmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <stdio.h>\n",
        "\n",
        "void addArrays(int* a , int* b ,int* c ,int count){\n",
        "    for (int i = 0; i< count ; ++i){\n",
        "        c[i] = a[i]+b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main (){\n",
        "    const int count = 5;\n",
        "    int a[] = {1, 2, 3, 4, 5};\n",
        "    int b[] = {10, 20, 30, 40, 50};\n",
        "    int c[count];\n",
        "\n",
        "    addArrays(a,b,c,count);\n",
        "\n",
        "    for (int i = 0; i< count ; ++i){\n",
        "      printf(\"%d \",c[i]);\n",
        "    }\n",
        "    \n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdN5xHemKEGt",
        "outputId": "0d41496b-e758-414d-9094-33d573bb31c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 22 33 44 55 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simulating multible threads"
      ],
      "metadata": {
        "id": "NST_sRQtIkoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <stdio.h>\n",
        "\n",
        "void addArrays(int* a , int* b ,int* c ,int i){\n",
        "    c[i] = a[i]+b[i];\n",
        "}\n",
        "\n",
        "int main (){\n",
        "    const int count = 5;\n",
        "    int a[] = {1, 2, 3, 4, 5};\n",
        "    int b[] = {10, 20, 30, 40, 50};\n",
        "    int c[count];\n",
        "\n",
        "  for (int i = 0; i< count ; ++i){\n",
        "      addArrays(a,b,c,i);\n",
        "  }\n",
        "\n",
        "    for (int i = 0; i< count ; ++i){\n",
        "      printf(\"%d \",c[i]);\n",
        "    }\n",
        "    \n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGMJ46XQOKR9",
        "outputId": "80c23a29-6a77-44f8-dc7c-c5046afd59e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 22 33 44 55 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transioning from CPU To GPU :\n",
        "- ##### A function to run on GPU (a kernel) is defined using \"__ global __\" declaration specifier indicating that the corresponding function is to be called from the host and executed on a device.\n",
        "\n",
        "- ##### CUDA operates on device memory , cannot operate on host memory: \n",
        " - cudaMalloc -> for allocating memory on the device  \n",
        " - cudaMemcpy -> for copying data between host and device \n",
        "\n",
        "- ##### Dimensions of Grid and block is specified on kernel invocation in dim3 structure\n",
        "- ##### Thread index i is an implicit variable ; A runing thread has all the information about the execution parameters as well as its own position on the grid and thread block"
      ],
      "metadata": {
        "id": "aB6RsHGXIqr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void addArrays(int* a , int* b ,int* c ){\n",
        "    \n",
        "    int i = threadIdx.x ; // threadid is var that contains the pos of this kernel as it's executing in a thread block\n",
        "    c[i] = a[i]+b[i] ;\n",
        "}\n",
        "\n",
        "int main (){\n",
        "    const int count = 5;\n",
        "    const int size = count * sizeof(int);\n",
        "    int ha[] = {1, 2, 3, 4, 5};  // h stands for host (smth runs on the cpu)\n",
        "    int hb[] = {10, 20, 30, 40, 50};\n",
        "    int hc[count];\n",
        "\n",
        "    // Allocate some mem for these data to be copied from the host to the device\n",
        "    int *da, *db, *dc;\n",
        "    cudaMalloc (&da, size);\n",
        "    cudaMalloc (&db, size);\n",
        "    cudaMalloc (&dc, size);\n",
        "\n",
        "    // copy the harrays into\n",
        "    cudaMemcpy(da,ha,size,cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(db,hb,size,cudaMemcpyHostToDevice);\n",
        "\n",
        "    // 1 block , count threads in it\n",
        "    addArrays<<<1,count>>>(da,db,dc);\n",
        "\n",
        "    // back to host \n",
        "    cudaMemcpy(hc,dc,size,cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for (int i = 0; i< count ; ++i){\n",
        "      printf(\"%d \",hc[i]);\n",
        "    }\n",
        "\n",
        "    //cleaning up\n",
        "    cudaFree(da);\n",
        "    cudaFree(db);\n",
        "    cudaFree(dc);\n",
        "    \n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YJrN7-IWiDB",
        "outputId": "2cbbe8b3-7b3d-4930-8337-69c2158722b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 22 33 44 55 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Device Query"
      ],
      "metadata": {
        "id": "olqah5EeRpeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quering device parameters"
      ],
      "metadata": {
        "id": "l0AZQyNMPxib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "int main(){\n",
        "    int count;\n",
        "    cudaGetDeviceCount(&count);\n",
        "    \n",
        "\n",
        "    // To get information about a particular device \n",
        "\n",
        "    cudaDeviceProp prop;\n",
        "    for (int i =0 ; i<count ; ++i){\n",
        "        cudaGetDeviceProperties(&prop , i);\n",
        "        cout<<\"Device \"<<i <<\": \"<< prop.name << endl ;\n",
        "        cout<<\"Compute capapility \"<<\": \"<< prop.major <<\".\"<< prop.minor << endl ;\n",
        "        cout<<\"Max Grid Dim :( \"<< prop.maxGridSize[0] << \" x \" << prop.maxGridSize[1] << \" x \" << prop.maxGridSize[2] << \") \"<< endl ;\n",
        "        cout<<\"Max BLock Dim :( \"<< prop.maxThreadsDim[0] << \" x \" << prop.maxThreadsDim[1] << \" x \" << prop.maxThreadsDim[2] << \") \"<< endl ;\n",
        "\n",
        "\n",
        "    }\n",
        "    return(0);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ONhKEammAUR",
        "outputId": "9fc37efa-11d7-4c8a-f966-cf9aeb83d625"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device 0: Tesla T4\n",
            "Compute capapility : 7.5\n",
            "Max Grid Dim :( 2147483647 x 65535 x 65535) \n",
            "Max BLock Dim :( 1024 x 1024 x 64) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parallel programming patterns"
      ],
      "metadata": {
        "id": "DGxta1hFtsYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Map"
      ],
      "metadata": {
        "id": "1JPKSgJht1wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name my_curand.cu \n",
        "\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include \"cuda.h\"\n",
        "#include \"curand.h\"\n",
        "\n",
        "#include <ctime>\n",
        "#include <cstdio>\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "\n",
        "__global__ void addTen(float *d,int count)\n",
        "{\n",
        "    int threadsPerBlock = blockDim.x * blockDim.y * blockDim.z;\n",
        "    int threadPosInBlock = threadIdx.x + blockDim.x * threadIdx.y + blockDim.x * blockDim.y * threadIdx.z;     \n",
        "    int blockPosInGrid = blockIdx.x + gridDim.x * blockIdx.y + gridDim.x * gridDim.y * blockIdx.z;  \n",
        "    int tid = blockPosInGrid * threadsPerBlock + threadPosInBlock ;\n",
        "\n",
        "    if (tid<count){\n",
        "        d[tid] = d[tid]+10;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    curandGenerator_t gen;\n",
        "    curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_MTGP32);\n",
        "    curandSetPseudoRandomGeneratorSeed(gen, time(0));\n",
        "\n",
        "    const int count = 123456;\n",
        "    const int size = count * sizeof(float);\n",
        "    float *d;\n",
        "    float h[count];\n",
        "    cudaMalloc(&d,size); \n",
        "\n",
        "    //initializing the array \n",
        "    curandGenerateUniform(gen, d , count); \n",
        "    \n",
        "    //kernel dimension\n",
        "    dim3 block(8,8,8);\n",
        "    dim3 grid(16,16);\n",
        "\n",
        "    addTen<<<grid,block>>>(d,count);\n",
        "\n",
        "    cudaMemcpy(h,d,size,cudaMemcpyDeviceToHost);\n",
        "    cudaFree(d);\n",
        "\n",
        "    for(int i =0; i< 100;++i){\n",
        "        cout << h[i] <<\" \" ;\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ovHUV2edSaMN",
        "outputId": "c9e97f44-003d-4441-eb0f-83d395ec0f62"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/my_curand.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o /content/src/my_curand /content/src/my_curand.cu -lcurand\n",
        "!/content/src/my_curand"
      ],
      "metadata": {
        "id": "_1-SrqF3vV83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e94ad33-8a9d-4ea6-9ea4-cb349b746d20"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.0852 10.3286 10.5196 10.3174 10.9631 10.444 10.9331 10.3817 10.6773 10.2615 10.6371 10.7809 10.0257 10.9503 10.4384 10.2716 10.3638 10.5453 10.5524 10.2075 10.3764 10.5308 10.3242 10.5421 10.0548 10.7493 10.1657 10.5587 10.519 10.2286 10.3594 10.4039 10.6184 10.3901 10.5421 10.4287 10.203 10.938 10.1874 10.0178 10.2055 10.3246 10.4924 10.7729 10.9913 10.3417 10.2838 10.2943 10.5655 10.1501 10.8893 10.8567 10.8777 10.902 10.4013 10.4166 10.6831 10.7198 10.3484 10.3256 10.4042 10.497 10.2061 10.1565 10.9536 10.7907 10.4115 10.0889 10.0524 10.7304 10.2368 10.6228 10.3419 10.5986 10.5086 10.2193 10.1952 10.0249 10.0181 10.4106 10.167 10.6811 10.8587 10.4183 10.218 10.9605 10.6729 10.3096 10.2346 10.6893 10.1103 10.8155 10.9644 10.7093 10.2212 10.0123 10.3107 10.646 10.2648 10.3904 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Black Scholes"
      ],
      "metadata": {
        "id": "UVPkHMnMWzz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name black_scholes.cu \n",
        "\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include \"curand.h\"\n",
        "#define _USE_MATH_DEFINES\n",
        "#include <ctime>\n",
        "#include <cstdio>\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "using namespace std;\n",
        "\n",
        "__device__ __host__ __inline__ float N(float x)\n",
        "{\n",
        "\treturn 0.5 + 0.5*erf(x*M_SQRT1_2);\n",
        "}\n",
        "\n",
        "__device__ __host__ void price(float k, float s, float t, float r, float v, float* c, float* p)\n",
        "{\n",
        "\tfloat srt = v * sqrtf(t);\n",
        "\tfloat d1 = (logf(s/k)+(r+0.5*v*v)*t) / srt;\n",
        "\tfloat d2 = d1 - srt;\n",
        "\tfloat kert = k * expf(-r*t);\n",
        "\t*c = N(d1)*s - N(d2)*kert;\n",
        "\t*p = kert - s + *c;\n",
        "}\n",
        "\n",
        "__global__ void price(float* k,float* s,float* t,float* r,float* v,float* c,float* p){\n",
        "    int idx = threadIdx.x;\n",
        "    price(k[idx] , s[idx] , t[idx] , r[idx] , v[idx] , &c[idx] , &p[idx] );\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tconst int count = 512;\n",
        "\tcurandStatus_t curandStatus;\n",
        "\tcudaError_t cudaError;\n",
        "\tfloat* args[5];\n",
        "\tcurandGenerator_t gen;\n",
        "\tcurandStatus = curandCreateGenerator(&gen, curandRngType_t::CURAND_RNG_PSEUDO_MTGP32);\n",
        "\tfor (int i = 0; i < 5; ++i) \n",
        "\t{\n",
        "\t\tcudaMalloc(&args[i], sizeof(float)*1024);\n",
        "\t\tcurandStatus = curandGenerateUniform(gen, args[i], count);\n",
        "\t}\n",
        "\n",
        "\tfloat *dc, *dp;\n",
        "\tcudaError = cudaMalloc(&dc, count*sizeof(float));\n",
        "\tcudaError = cudaMalloc(&dp, count*sizeof(float));\n",
        "\n",
        "\tprice<<<1,count>>>(args[0], args[1], args[2], args[3], args[4], dc, dp);\n",
        "\n",
        "\tfloat hc[count] = { 0 };\n",
        "\tfloat hp[count] = { 0 };\n",
        "\tcudaMemcpy(hc, dc, sizeof(float)*count, cudaMemcpyKind::cudaMemcpyDeviceToHost);\n",
        "\tcudaMemcpy(hp, dp, sizeof(float)*count, cudaMemcpyKind::cudaMemcpyDeviceToHost);\n",
        "\n",
        "\tcudaFree(dc);\n",
        "\tcudaFree(dp);\n",
        "\tfor (int i = 0; i < 5; ++i)\n",
        "\t\tcudaFree(&args[i]);\n",
        "\tcudaDeviceReset();\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "e84gXtQSPCov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f509c97a-d72c-4fe8-c869-ca55c5ba09c8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/black_scholes.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o /content/src/black_scholes /content/src/black_scholes.cu -lcurand\n",
        "!/content/src/black_scholes"
      ],
      "metadata": {
        "id": "jtr6AF7NTxap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Atomic operations"
      ],
      "metadata": {
        "id": "CKEEEo2Zm6FN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Atomic sum"
      ],
      "metadata": {
        "id": "fvKCmk1ckEuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include \"sm_20_atomic_functions.h\"\n",
        "\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "__device__ int dSum = 0;\n",
        "\n",
        "__global__ void sum(int* d)\n",
        "{\n",
        "    int tid = threadIdx.x;\n",
        "    //dSum += d[tid];   //this will go wrong as when in several threads in parallel\n",
        "    atomicAdd(&dSum,d[tid]);\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "    const int count = 128;\n",
        "    const int size = count * sizeof(int);\n",
        "  \n",
        "    int h[count];\n",
        "    for (int i =0 ; i<count;i++)\n",
        "    {\n",
        "        h[i] = i+1;\n",
        "    }\n",
        " \n",
        "    int* d;\n",
        "    cudaMalloc(&d ,size );\n",
        "    cudaMemcpy(d,h,size,cudaMemcpyHostToDevice);\n",
        "    sum<<<1,count>>>(d);\n",
        " \n",
        "    int hSum;\n",
        "\n",
        "    cudaMemcpyFromSymbol(&hSum , dSum, sizeof(int));\n",
        "    cout<< \"the sum of nums from 1 to \"<<count << \" is: \" << hSum <<endl;\n",
        " \n",
        "    cudaFree(d);\n",
        "    return 0;\n",
        " \n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFsU7P8Gm_Sx",
        "outputId": "be3b06b7-4d11-4bd5-87a0-d0b0d8fbb079"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the sum of nums from 1 to 128 is: 8256\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monte Carlo Pi"
      ],
      "metadata": {
        "id": "TU_NI-fYpg_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name MonteCarloPi.cu \n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include \"sm_20_atomic_functions.h\"\n",
        "#include \"curand.h\"\n",
        "\n",
        "#include <ctime>\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__device__ int dCount = 0;\n",
        "\n",
        "__global__ void countPoints(const float* xs, const float* ys )\n",
        "{\n",
        "    int idx = blockIdx.x + blockDim.x + threadIdx.x;\n",
        "    float x = xs[idx] - 0.5f;\n",
        "    float y = ys[idx] - 0.5f;\n",
        "    int n = sqrt(x*x+y*y) > 0.5f ? 0 : 1;\n",
        "    atomicAdd(&dCount,n);\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "    const int count = 512*512;\n",
        "    const int size = count * sizeof(float);\n",
        "\n",
        "    cudaError_t cudaStatus;\n",
        "    curandStatus_t curandStatus;\n",
        "    curandGenerator_t gen;\n",
        " \n",
        "    //initialize the 512*512 array of rand points\n",
        "    curandStatus = curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_MTGP32);\n",
        "    curandSetPseudoRandomGeneratorSeed(gen, time(0));\n",
        " \n",
        "    //initializaing x, y coordinate arrays\n",
        "    float* x;\n",
        "    float* y;\n",
        "    cudaStatus = cudaMalloc(&x ,size );\n",
        "    cudaStatus = cudaMalloc(&y ,size );\n",
        "    curandStatus = curandGenerateUniform(gen, x, count);\n",
        "    curandStatus = curandGenerateUniform(gen, y, count);\n",
        " \n",
        "    //count points\n",
        "    countPoints<<<512,512>>>(x,y);\n",
        "\n",
        "    int hCount;\n",
        "\n",
        "    cudaMemcpyFromSymbol(&hCount, dCount, sizeof(int));\n",
        " \n",
        "    cudaFree(x);\n",
        "    cudaFree(y);\n",
        " \n",
        "    cout << setprecision(12) \n",
        "         << \"Pi is approximately \" \n",
        "         << (4.0f * (float)hCount)/ (float)count << endl;\n",
        "    \n",
        "    return 0;\n",
        " \n",
        "}"
      ],
      "metadata": {
        "id": "Qu-QzBhapoVq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6047ecd8-1dbd-4f23-d7fb-7eddded303f2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/MonteCarloPi.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the code\n",
        "!nvcc -o /content/src/MonteCarloPi /content/src/MonteCarloPi.cu -lcurand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVUGazlbakcs",
        "outputId": "d6d53265-bbca-4498-8c3f-7cc7526f6a2e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/src/MonteCarloPi.cu(28): warning: variable \"cudaStatus\" was set but never used\n",
            "\n",
            "/content/src/MonteCarloPi.cu(29): warning: variable \"curandStatus\" was set but never used\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the code\n",
        "!/content/src/MonteCarloPi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEvDlmCMZliv",
        "outputId": "ae25f3dc-e747-4ecc-9dc5-d9a1db64216d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pi is approximately 3.17822265625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA Events"
      ],
      "metadata": {
        "id": "1CAkTt6A2QWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include \"sm_20_atomic_functions.h\"\n",
        "\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "__device__ int dSum = 0;\n",
        "\n",
        "__global__ void sum(int* d)\n",
        "{\n",
        "    int tid = threadIdx.x;\n",
        "    //dSum += d[tid]; //this will go wrong as when in several threads in parallel\n",
        "    atomicAdd(&dSum,d[tid]);\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "    const int count = 128;\n",
        "    const int size = count * sizeof(int);\n",
        "  \n",
        "    int h[count];\n",
        "    for (int i =0 ; i<count;i++)\n",
        "    {\n",
        "        h[i] = i+1;\n",
        "    }\n",
        " \n",
        "    int* d;\n",
        "    cudaMalloc(&d ,size );\n",
        "    cudaMemcpy(d,h,size,cudaMemcpyHostToDevice);\n",
        "    \n",
        "    // create events\n",
        "    cudaEvent_t start, end ;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    sum<<<1,count>>>(d);\n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        " \n",
        "    float elapsed;\n",
        " \n",
        "    cudaEventElapsedTime(&elapsed,start,end);\n",
        " \n",
        "    int hSum;\n",
        "\n",
        "    cudaMemcpyFromSymbol(&hSum , dSum, sizeof(int));\n",
        "    cout<< \"the sum of nums from 1 to \"<<count << \" is: \" << hSum << \", and it took: \"<<elapsed<<\" ms\" <<endl;\n",
        " \n",
        "    cudaFree(d);\n",
        "    return 0;\n",
        " \n",
        "} "
      ],
      "metadata": {
        "id": "cNPY2hNCbhWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84dd5211-05da-42ec-dd92-f482c0854ec8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the sum of nums from 1 to 128 is: 8256, and it took: 0.01648 ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pinned memory performance speed up"
      ],
      "metadata": {
        "id": "NEEcDdg3uqC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "float timeMemory(bool pinned, bool toDevice)\n",
        "{\n",
        "    const int count = 1 << 20;\n",
        "    const int iterations = 1 << 6;\n",
        "    const int size = count * sizeof(int);\n",
        " \n",
        "    cudaEvent_t start , end;\n",
        "    int *h,*d;\n",
        "    float elapsed;\n",
        "    cudaError_t status;\n",
        " \n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "\n",
        "    cudaMalloc(&d, size);\n",
        "    if(pinned)\n",
        "      cudaHostAlloc(&h, size, cudaHostAllocDefault);\n",
        "    else\n",
        "      h = new int[count]; //or malloc;\n",
        " \n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    for (int i = 0 ; i < iterations ; ++i){\n",
        "        if (toDevice){\n",
        "            status = cudaMemcpy(d, h, size, cudaMemcpyHostToDevice);\n",
        "        }\n",
        "        else{\n",
        "            status = cudaMemcpy(h, d, size, cudaMemcpyDeviceToHost);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        "    cudaEventElapsedTime(&elapsed, start, end);\n",
        "\n",
        "    if(pinned)\n",
        "      cudaFreeHost(h);\n",
        "    else\n",
        "      delete [] h;\n",
        " \n",
        "    cudaFree(d);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(end);\n",
        "\n",
        "    return elapsed;\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main ()\n",
        "{\n",
        "    cout << \"From device, paged memory:\\t\" << timeMemory(false, false) << endl;  \n",
        "    cout << \"To device, paged memory:\\t\" << timeMemory(false, true) << endl;  \n",
        "    cout << \"From device, pinned memory:\\t\" << timeMemory(true, false) << endl;  \n",
        "    cout << \"To device, pinned memory:\\t\" << timeMemory(true, true) << endl;  \n",
        "\n",
        "    return 0;\n",
        " \n",
        "} "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZURlH8dlfV64",
        "outputId": "e4a93fc3-0c92-4980-cc7b-12a84b9a7f17"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From device, paged memory:\t64.4473\n",
            "To device, paged memory:\t59.5559\n",
            "From device, pinned memory:\t21.3924\n",
            "To device, pinned memory:\t23.2829\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single stream"
      ],
      "metadata": {
        "id": "0fxs8S6tn1s9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using a single stream and queing up operations on it\n",
        "\n",
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "#include <ctime>\n",
        "using namespace std;\n",
        "\n",
        "//several chunks of elements \n",
        "const int chunkCount = 1 << 20;\n",
        "const int totalCount = chunkCount << 3;\n",
        "\n",
        "\n",
        "__global__ void kernel(float* a, float* b, float* c)\n",
        "{\n",
        "    int tid = blockDim.x*blockIdx.x+threadIdx.x;\n",
        "    if (tid < chunkCount)\n",
        "      c[tid] = erff(a[tid]+b[tid]);\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "      \n",
        "    cudaEvent_t start , end;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "\n",
        "    cudaStream_t stream;\n",
        "    cudaStreamCreate(&stream);\n",
        " \n",
        "    float *ha, *hb, *hc, *da, *db, *dc;\n",
        "    const int totalSize = totalCount * sizeof(float);\n",
        "    const int chunkSize = chunkCount * sizeof(float);\n",
        " \n",
        "    // allocate memory\n",
        "    cudaMalloc(&da, chunkSize);\n",
        "    cudaMalloc(&db, chunkSize);\n",
        "    cudaMalloc(&dc, chunkSize);\n",
        " \n",
        "    cudaHostAlloc(&ha , totalSize, cudaHostAllocDefault);\n",
        "    cudaHostAlloc(&hb , totalSize, cudaHostAllocDefault);\n",
        "    cudaHostAlloc(&hc , totalSize, cudaHostAllocDefault);\n",
        " \n",
        "    // fill a and b with noise on the cpu side\n",
        "    srand((unsigned)time(0));\n",
        "    for (int i = 0; i < totalCount ; i++)\n",
        "    {\n",
        "        ha[i] = rand() / RAND_MAX;\n",
        "        hb[i] = rand() / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    cudaEventRecord(start, stream);\n",
        "    //send sequentially chunks of data to the kernel\n",
        "    for (int i = 0 ; i < totalCount ; i+=chunkCount)\n",
        "    {\n",
        "        cudaMemcpyAsync(da, ha+i, chunkSize, cudaMemcpyHostToDevice,stream); //queue data up for the stream to do it\n",
        "        cudaMemcpyAsync(db, hb+i, chunkSize, cudaMemcpyHostToDevice,stream);\n",
        "        kernel<<<chunkCount/64,4,0,stream>>>(da,db,dc);\n",
        "        cudaMemcpyAsync(hc+i, dc, chunkSize, cudaMemcpyDeviceToHost,stream); \n",
        "    }\n",
        "    cudaStreamSynchronize(stream);\n",
        " \n",
        "    cudaEventRecord(end,stream);\n",
        "    cudaEventSynchronize(end);\n",
        "    \n",
        "    float elapsed;  \n",
        "    cudaEventElapsedTime(&elapsed, start, end);\n",
        "    cout << \"This took: \" << elapsed << \" msec\" <<endl;\n",
        "    \n",
        "    cudaFreeHost(ha);\n",
        "    cudaFreeHost(hb);\n",
        "    cudaFreeHost(hc);\n",
        "    cudaFree(da);\n",
        "    cudaFree(db);\n",
        "    cudaFree(dc);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(end);\n",
        "    cudaStreamDestroy(stream);\n",
        "    return 0;\n",
        " \n",
        "} "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPzHsU4jgu_w",
        "outputId": "a83ed640-b00c-4ffc-ff60-369111a0ecc1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This took: 8.68624 msec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Streams"
      ],
      "metadata": {
        "id": "1vOkrFp02I-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using a single stream and queing up operations on it\n",
        "\n",
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "#include <ctime>\n",
        "using namespace std;\n",
        "\n",
        "//several chunks of elements \n",
        "const int chunkCount = 1 << 20;\n",
        "const int totalCount = chunkCount << 3;\n",
        "\n",
        "\n",
        "__global__ void kernel(float* a, float* b, float* c)\n",
        "{\n",
        "    int tid = blockDim.x*blockIdx.x+threadIdx.x;\n",
        "    if (tid < chunkCount)\n",
        "      c[tid] = erff(a[tid]+b[tid]);\n",
        "}\n",
        "\n",
        "int main ()\n",
        "{\n",
        "      \n",
        "    cudaEvent_t start , end;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "\n",
        "    cudaStream_t stream1;\n",
        "    cudaStream_t stream2;\n",
        "    cudaStreamCreate(&stream1);\n",
        "    cudaStreamCreate(&stream2);\n",
        " \n",
        "    float *ha, *hb, *hc, *d1a, *d1b, *d1c, *d2a, *d2b, *d2c;\n",
        "    const int totalSize = totalCount * sizeof(float);\n",
        "    const int chunkSize = chunkCount * sizeof(float);\n",
        " \n",
        "    // allocate memory\n",
        "    cudaMalloc(&d1a, chunkSize);\n",
        "    cudaMalloc(&d1b, chunkSize);\n",
        "    cudaMalloc(&d1c, chunkSize);\n",
        "    cudaMalloc(&d2a, chunkSize);\n",
        "    cudaMalloc(&d2b, chunkSize);\n",
        "    cudaMalloc(&d2c, chunkSize);\n",
        " \n",
        "    cudaHostAlloc(&ha , totalSize, cudaHostAllocDefault);\n",
        "    cudaHostAlloc(&hb , totalSize, cudaHostAllocDefault);\n",
        "    cudaHostAlloc(&hc , totalSize, cudaHostAllocDefault);\n",
        " \n",
        "    // fill a and b with noise on the cpu side\n",
        "    srand((unsigned)time(0));\n",
        "    for (int i = 0; i < totalCount ; i++)\n",
        "    {\n",
        "        ha[i] = rand() / RAND_MAX;\n",
        "        hb[i] = rand() / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    cudaEventRecord(start, stream1);\n",
        "    //send sequentially chunks of data to the kernel\n",
        "    for (int i = 0 ; i < totalCount ; i+=chunkCount*2)\n",
        "    {\n",
        "\n",
        "        cudaMemcpyAsync(d1a, ha+i, chunkSize, cudaMemcpyHostToDevice,stream1); //queue data up for the stream to do it\n",
        "        cudaMemcpyAsync(d2a, ha+i+chunkCount, chunkSize, cudaMemcpyHostToDevice,stream2); //queue data up for the stream to do it\n",
        "        cudaMemcpyAsync(d1b, hb+i, chunkSize, cudaMemcpyHostToDevice,stream1);\n",
        "        cudaMemcpyAsync(d2b, hb+i+chunkCount, chunkSize, cudaMemcpyHostToDevice,stream2);\n",
        "        kernel<<<chunkCount/64,4,0,stream1>>>(d1a,d1b,d1c);\n",
        "        kernel<<<chunkCount/64,4,0,stream2>>>(d2a,d2b,d2c);\n",
        "\n",
        "        cudaMemcpyAsync(hc+i, d1c, chunkSize, cudaMemcpyDeviceToHost,stream1);    \n",
        "        cudaMemcpyAsync(hc+i+chunkCount, d2c, chunkSize, cudaMemcpyDeviceToHost,stream2);    \n",
        "      \n",
        "\n",
        "    }\n",
        "    cudaStreamSynchronize(stream1);\n",
        "    cudaStreamSynchronize(stream2);\n",
        " \n",
        "    cudaEventRecord(end,stream2);\n",
        "    cudaEventSynchronize(end);\n",
        "    \n",
        "    float elapsed;  \n",
        "    cudaEventElapsedTime(&elapsed, start, end);\n",
        "    cout << \"This took: \" << elapsed << \" msec\" <<endl;\n",
        "    \n",
        "    cudaFreeHost(ha);\n",
        "    cudaFreeHost(hb);\n",
        "    cudaFreeHost(hc);\n",
        "   \n",
        "    cudaStreamDestroy(stream1);\n",
        "    cudaStreamDestroy(stream2);\n",
        "    return 0;\n",
        " \n",
        "} "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWULVGrf1e5U",
        "outputId": "14a0e944-173a-49b2-95a5-bf494a7befb3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This took: 6.32221 msec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thrust"
      ],
      "metadata": {
        "id": "9_Nbpbad-fYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file thrust_example.cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/sort.h>\n",
        "\n",
        "#include <ctime>\n",
        "using namespace std;\n",
        "\n",
        "int myrand()\n",
        "{\n",
        "    return rand() % 10;\n",
        "}\n",
        "int main()\n",
        "{\n",
        "    int count = 1024;\n",
        "    thrust::host_vector<int> h(count);\n",
        "    generate(begin(h),end(h),myrand);\n",
        "    thrust::device_vector<int> d = h;\n",
        "    thrust::sort(begin(d), end(d));\n",
        "    h =d ;\n",
        "    for(int i = 0; i<count ; i++)\n",
        "    {\n",
        "        cout << h[i] <<\"\\t\";\n",
        "    }\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a-ui714I5Zr",
        "outputId": "b3f73d8f-4133-46b8-b0d7-814153ccf8da"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing thrust_example.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc thrust_example.cu -o thrust_example\n",
        "!./thrust_example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3NRTJYGCDXA",
        "outputId": "9c9168b4-2707-46c1-e5a6-c004fb1cf49e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t2\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t3\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t4\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t5\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t6\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t7\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t9\t"
          ]
        }
      ]
    }
  ]
}